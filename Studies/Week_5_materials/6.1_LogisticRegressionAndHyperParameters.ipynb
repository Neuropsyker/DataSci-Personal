{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the hyperparameters\n",
    "\n",
    "Hyperparameters in machine learning are parameters whose values are set before the learning process begins. Unlike model parameters, which are learned from the data, hyperparameters are more like higher-level settings for the algorithm that guide the learning process. They are crucial in determining the behavior of the training algorithm and the performance of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of hyperparameters\n",
    "\n",
    "1. Learning Rate: In many algorithms, especially those involving gradient descent, the learning rate determines how much the model's weights are updated during training. A too high learning rate can cause the model to converge too quickly to a suboptimal solution, while a too low learning rate can make the training process very slow.\n",
    "\n",
    "2. Number of Epochs: This is the number of times the learning algorithm will work through the entire training dataset.\n",
    "\n",
    "3. Batch Size: In mini-batch gradient descent, this hyperparameter defines the number of samples to work through before updating the internal model parameters.\n",
    "\n",
    "4. Tree-Specific Parameters: In algorithms like decision trees and ensemble methods (like random forests, gradient boosting), hyperparameters include the depth of the tree, number of trees, and minimum number of samples required at a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters in Logistic Regression \n",
    "\n",
    "1. Penalty\n",
    "2. solver: 'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the exercises for today is to review this! :)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
