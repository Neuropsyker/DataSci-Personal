{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is a fundamental optimisation algorithm in machine learning. \n",
    "\n",
    "- It's useful for training models such as linear regression and neural nets\n",
    "- It does this by finding the set of parameters (weights) that minimise the cost / loss function\n",
    "- The aim is to find the minimum of a cost function $$ J(\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent is a fundamental optimization algorithm used in machine learning and deep learning to minimize a function. It's particularly useful for training models, where the function represents the cost or error that the model needs to minimize.\n",
    "\n",
    "Here's a breakdown of how Gradient Descent works:\n",
    "\n",
    "1. **Objective Function**:\n",
    "   - The goal is to minimize an objective function $J(\\theta)$, where $\\theta$ represents the parameters of the model.\n",
    "\n",
    "2. **Gradient Calculation**:\n",
    "   - The gradient of $J(\\theta)$ with respect to $\\theta$ is calculated. The gradient $\\nabla_{\\theta} J(\\theta)$ is a vector that points in the direction of the steepest increase of $J$.\n",
    "\n",
    "3. **Update Rule**:\n",
    "   - The parameters $\\theta$ are updated in the opposite direction of the gradient to minimize $J$. The update rule is: $\\theta := \\theta - \\alpha \\nabla_{\\theta} J(\\theta)$.\n",
    "   - Here, $\\alpha$ is the learning rate, a positive scalar determining the size of the step.\n",
    "\n",
    "4. **Iteration**:\n",
    "   - This process is iterated until $J(\\theta)$ converges to a minimum.\n",
    "\n",
    "5. **Learning Rate**:\n",
    "   - The learning rate $\\alpha$ is crucial. If it's too small, convergence is slow. If it's too large, the algorithm might overshoot the minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants:\n",
    "- Batch Gradient Descent: Uses the entire training set to compute the gradient at each step.\n",
    "- Stochastic Gradient Descent (SGD): Uses one training example at each step. This can be faster and can help to avoid local minima, but is more erratic.\n",
    "- Mini-batch Gradient Descent: Uses a small random subset of the training data at each step. This is a compromise between Batch GD and SGD and is often used in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
