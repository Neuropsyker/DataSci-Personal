{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is data engineering?\n",
    "\n",
    "- Data engineering is like being a builder or an architect \n",
    "- Data is scattered around and a data engineer collects the materia and organises them neatly\n",
    "- They then work to organise them neatly and make sure that they are stored in an effective manner\n",
    "\n",
    "- Data engineer's job is to collect material so tha they can organise them neatly and in an effective manner\n",
    "- They build pipelines what are like conveyor belts and move data from one place to another and clean up, tranform it into a format that is useful and effective\n",
    "\n",
    "- This data is then effectively ingested by data scientist, data analysts and other team members\n",
    "- The value of good data engineering can be seen by a team having an effective system that allows them to handle data effectively and efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a database?\n",
    "\n",
    "- A database is a structured way to store, manage and retrieve data\n",
    "- Think of it like a digital filing system where information is kepy in an organised manner \n",
    "- There are different types of databases\n",
    "\n",
    "1. Structured databases \n",
    "- Databases store data in a structured format, often in tables \n",
    "- These tables are like spreadsheets (which have rows and columns)\n",
    "- Each row represents a record of information \n",
    "- Each colun represents a specific attribute or field of the record\n",
    "\n",
    "2. Relational Databases:\n",
    "- Use tables to store data \n",
    "\n",
    "3. NoSQL Databases: \n",
    "- Store data in formation other than tables \n",
    "- These can include key-value pairs (documents or graphs)\n",
    "- E.g. MongoDB, Cassandra and Neo4J\n",
    "\n",
    "4. Data Retrieval and Manipulation:\n",
    "- Databases use a query language like SQL to make retrieving, adding, updating and deleting data easier\n",
    "- By asking complex questions to the database you can get it ro return information based on the query\n",
    "\n",
    "5. Databases enforce rules to make sure that the data is accurate and consistent \n",
    "- The have measures to secure the data from unauthorised access or corruption \n",
    "\n",
    "6. Scalability and Performance: \n",
    "- Databases are designed to handle large amounts of data and manay users\n",
    "- They are essential for businesses and organisations that need to store and analyse large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a data warehouse?\n",
    "\n",
    "- A data warehouse is a type of database designed specifically for analysis and reporting\n",
    "- It is optimised for transaction processing (inserting, updating and deleting data)\n",
    "- Designed to consolidate data from multiple sources and organise it in an efficient way for querying\n",
    "\n",
    "\n",
    "1. They are combined from different sources (such as various business systems, applications, and external data)\n",
    "2. They are optimised for queries and analysis - they are optimised for querying large datasets and carrying out complex analyses\n",
    "3. They store historical data, which allows the analysis of trends overtime \n",
    "4. They have a star schema or a snowflake schema, and contain facts and dimension tables \n",
    "5. Data warehouses are integral to BI, and they provide the data foundation for reporting tools, dashboards and data analytics software \n",
    "6. They are seperate from operational databases, operational databases handle day-to-day transactions, this allows the systems performance to not be impacted by data analysis. \n",
    "7. ETL processes: extract, transfer, load processes are commonly used in data warehousing. Data is extracted from various sources, transformed into a suitable format and then loaded into the data warehouse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a data lake?\n",
    "\n",
    "- A data lake is a storage respository that holds a vast amount of raw data \n",
    "- It is stored in the native format until it is needed \n",
    "- It's optimised for storing big data \n",
    "- It handles various types of data (structured, semi-structured and unstructured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a lakehouse?\n",
    "\n",
    "- A lakehouse is a new term in data management, it represent a blend of concepts from data lakes to data warehouses \n",
    "- It combines the benefits of both systems to provide a unified data platform for data storage, management and analysis \n",
    "\n",
    "1. Combining data lake and data warehouse features \n",
    "2. It's a unified platform - the lakehouse provided a single platform where both structured and unstructued data can be stored, managed and analysed. It handles big data scale, like a data lake while also supporting the transactional and analytical capabilities of a data warehouse. \n",
    "3. It supports advanced analytics and machine learning \n",
    "4. Merging the functionalities of a data lake, warehouses etc mean that the datalake is more cost effective and scalable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the different data infrastructures?\n",
    "\n",
    "1. Databases \n",
    "2. Data warehouses\n",
    "3. Data lakes \n",
    "4. Data lakehouses \n",
    "5. Cloud-based data infrastructures \n",
    "6. Data processing frameworks (Hadoop, Spark)\n",
    "7. Streaming data platforms (Kafka, Flink)\n",
    "8. Data integration tools: ETL tools (services that allow you to integrate data from different sources)\n",
    "9. MDM (Master data management) - ensuring uniformity, accuracy, stewardship, consistency of the enterprices official master data assets\n",
    "10. Data governance and security tools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is SQL?\n",
    "\n",
    "- This stands for structured query language and it is a programming language designed for managing and manipulating relational databases. \n",
    "- It is the standard language for relational databases \n",
    "\n",
    "## What is SQL used for?\n",
    "- Data querying \n",
    "- Data manipulation \n",
    "- Creating databases and schemas \n",
    "- Data management \n",
    "- Standardisation (it's a standardised language recognised by many)\n",
    "- Widely used and lots of support available online\n",
    "- There are multiple variants of SQL such as (T-SQL, PL/SQL, Microsoft SQL Server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is AWS, Google Cloud and Azure?\n",
    "\n",
    "- AWS, GCP and Azure are the leading cloud computing platforms \n",
    "- They offer a wide range of services that cover various aspects of cloud computing \n",
    "\n",
    "#### AWS: (Built on Amazon)\n",
    "1. Offer a number of key services including; EC2, S3, RDS, Lambda \n",
    "2. For the data science work, sage maker is often used and is an effective way of exploring data \n",
    "\n",
    "#### GCP: (Built on Google)\n",
    "1. Offers a number of services: such as virtual machines for computing, databases and blob storage\n",
    "2. BigQuery: Serverless, highly scalable and cost-effective multi-cloud data warehouse (it allows tou to )\n",
    "\n",
    "#### Azure: (Built on Microsoft)\n",
    "1. Also offers a number of different services, such as virtual machines, SQL databases, blob storage and active directories \n",
    "2. Azure microservices\n",
    "\n",
    "What all 3 cloud providers do:\n",
    "\n",
    "1. Provide people with scalability and flexibility \n",
    "2. Global network of data centers\n",
    "3. Offer different services, such as compute power, storage options and networking capabilities \n",
    "4. Offer effective and scalable pricing models\n",
    "\n",
    "- AWS, GCP and Azure often depend on the specific needs of the busienss and the existing infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a data pipeline?\n",
    "\n",
    "- A data pipeline is the process for moving data from one system to another.\n",
    "- The process is often essential in data management and analysis \n",
    "- It ensures that data flows effcieintly from one source to another destination \n",
    "- It can be used for a variaty of purposes, such as analytics, reporting and machine learning \n",
    "\n",
    "1. Extraction: \n",
    "- Data is collected from various sources \n",
    "- The sources can be databases, cloud storage, APIs or flat files \n",
    "\n",
    "2. Transformation:\n",
    "- The data is extracted and it is transformed into a suitable format for analysis \n",
    "- This can include cleaning the data (such as removing duplicates, and handling missing values)\n",
    "- Converting data types\n",
    "- Normalising the data \n",
    "- Enriching the data by combinining it with multiple sources \n",
    "\n",
    "3. Loading:\n",
    "- Once the data is transformed it is loaded into the the system of choice (this can be the database, datawarehouse or data lake)\n",
    "- This depends on where the data needs to reside\n",
    "\n",
    "4. Batch vs Streaming: \n",
    "- Batch processing: is when the data is collected in batches and processes at specific intervals\n",
    "- Streaming processing: data is processed in real time as it's generated / received \n",
    "- It's essential for where immediate data processing and insights are required \n",
    "\n",
    "5. Automation and Orchestration: \n",
    "- Data pipelines are typically automates so that data flows continuously and efficiently and doesn't need much manual intervention\n",
    "- Pipeline orchestration incloves managing the interdependencies and execution order of various pipeline tasks\n",
    "\n",
    "6. Monitoring and maintenance:\n",
    "- It's important to monitor your data pipelines for errors and performance issues \n",
    "- Maintenance includes changing the pipeline to account for changing needs such as changing data sources, formats and processing needs\n",
    "\n",
    "7. Security and compliance \n",
    "- Ensuring the data securit and compliance is monitored and adhered to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Kafka?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kafka is a stream-processing software programme that was developed by Apache \n",
    "- It's designed to be a high throughput and low latency platform for handling real-time data \n",
    "- It's gained popularity for its robustness and scalability and high performance "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
