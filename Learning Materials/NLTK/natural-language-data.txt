It is very important to preprocess and tokenize words from language data because any machine learning model you build is only ever as good as the data that you feed into it. Improper preprocessing will produce a model that isn't very good at its job! Human language is filled with ambiguities that make it incredibly difficult to write software that accurately determines the intended meaning of text or voice data. Homonyms, homophones, sarcasm, idioms, metaphors, grammar and usage exceptions, variations in sentence structureâ€”these just a few of the irregularities of human language that take humans years to learn, but that programmers must teach natural language-driven applications to recognize and understand accurately from the start, if those applications are going to be useful.