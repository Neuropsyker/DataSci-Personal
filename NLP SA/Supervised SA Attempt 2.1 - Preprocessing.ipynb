{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a second attempt at the comment toxicity classification project, utilising a different methodology in the hope of achieving better metrics on the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import email\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import classify\n",
    "from sklearn import metrics, preprocessing, feature_extraction, linear_model, naive_bayes, ensemble, pipeline, svm, model_selection, decomposition\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import tree, datasets\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Bidirectional\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Ensure NLTK libraries up to date:\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tell TensorFlow to run all deep learning on GPU:\n",
    "tf.config.set_soft_device_placement\n",
    "tf.test.is_built_with_cuda()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for later use:\n",
    "\n",
    "# Feature extractor and vectorizer, to produce TF-IDF document matrix:\n",
    "def feature_vectorizer(corpus):\n",
    "    '''Preprocesses entire body of text data.'''\n",
    "    sa_stop_words = nltk.corpus.stopwords.words('english')\n",
    "    '''Create a list of exceptions, as these stopwords may change a sentence's sentiment if removed.'''\n",
    "    sa_white_list = ['what', 'but', 'if', 'because', 'as', 'until', 'against', 'up', 'down', 'in', 'out',\n",
    "                    'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'why',\n",
    "                    'how', 'all', 'any', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
    "                    'same', 'so', 'than', 'too', 'can', 'will', 'just', 'don', 'should']\n",
    "    '''Remove stop words except for those specified in the white list.'''\n",
    "    sa_stop_words = [sw for sw in sa_stop_words if sw not in sa_white_list]\n",
    "    '''Instantiate the vectorizer.'''\n",
    "    count_vectorizer = feature_extraction.text.CountVectorizer(\n",
    "        lowercase=True,\n",
    "        tokenizer=nltk.word_tokenize,\n",
    "        min_df=2,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=sa_stop_words\n",
    "    )\n",
    "    '''Run the vectorizer on the body of text ('corpus').'''\n",
    "    processed_corpus = count_vectorizer.fit_transform(corpus)\n",
    "    processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform(processed_corpus)\n",
    "    return processed_corpus\n",
    "\n",
    "\n",
    "# Data checker to perform basic EDA and check for nulls, duplicates, etc.\n",
    "def data_integrity_check(df, title='', include_non_numeric=True):\n",
    "    results = []\n",
    "    for col in df:\n",
    "        result = {\n",
    "            'Column': col,\n",
    "            'Null Values': df[col].isnull().sum(),\n",
    "            'Duplicate Values': df[col].duplicated().sum(),\n",
    "            'Data Type': df[col].dtype\n",
    "        }\n",
    "        if include_non_numeric or df[col].dtype in ['int64', 'float64']:\n",
    "            result['Unique Values'] = df[col].nunique()\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                result['Mean'] = df[col].mean()\n",
    "                result['Median'] = df[col].median()\n",
    "                result['Mode'] = stats.mode(df[col])\n",
    "                result['Range'] = df[col].max() - df[col].min()\n",
    "                result['Skew'] = df[col].skew()\n",
    "                result['Kurtosis'] = df[col].kurtosis()\n",
    "        if df[col].dtype == 'object':  \n",
    "            result['Min Text Length'] = df[col].str.len().min()\n",
    "            result['Max Text Length'] = df[col].str.len().max()\n",
    "            '''Calculate mean and median text lengths'''\n",
    "            text_lengths = df[col].str.len()\n",
    "            result['Mean Text Length'] = np.mean(text_lengths)\n",
    "            result['Median Text Length'] = np.median(text_lengths)\n",
    "        results.append(result)\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df['Source'] = title\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (159571, 8)\n",
      "Training Data Columns:  Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate'],\n",
      "      dtype='object')\n",
      "Test Label Data Shape:  (153164, 7)\n",
      "Test Label Data Columns:  Index(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
      "       'identity_hate'],\n",
      "      dtype='object')\n",
      "Test Data Shape:  (153164, 2)\n",
      "Test Data Columns:  Index(['id', 'comment_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load in datasets.\n",
    "\n",
    "# Training data with text and classifications:\n",
    "df_train = pd.read_csv('sa_train.csv')\n",
    "\n",
    "# Classification labels for test data:\n",
    "df_test_labels = pd.read_csv('sa_test_labels.csv')\n",
    "\n",
    "# Test data with text only:\n",
    "df_test_data = pd.read_csv('sa_test_data.csv')\n",
    "\n",
    "print(f'Training Data Shape: ', df_train.shape)\n",
    "print(f'Training Data Columns: ', df_train.columns)\n",
    "print(f'Test Label Data Shape: ', df_test_labels.shape)\n",
    "print(f'Test Label Data Columns: ', df_test_labels.columns)\n",
    "print(f'Test Data Shape: ', df_test_data.shape)\n",
    "print(f'Test Data Columns: ', df_test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Null Values</th>\n",
       "      <th>Duplicate Values</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Min Text Length</th>\n",
       "      <th>Max Text Length</th>\n",
       "      <th>Mean Text Length</th>\n",
       "      <th>Median Text Length</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Range</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>159571</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.000420</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment_text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>159571</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>396.593961</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>159569</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 144277)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.745854</td>\n",
       "      <td>5.539784</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>159569</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 157976)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.851722</td>\n",
       "      <td>95.057627</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0</td>\n",
       "      <td>159569</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 151122)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.992817</td>\n",
       "      <td>13.942760</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threat</td>\n",
       "      <td>0</td>\n",
       "      <td>159569</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 159093)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.189001</td>\n",
       "      <td>328.843890</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>insult</td>\n",
       "      <td>0</td>\n",
       "      <td>159569</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 151694)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.160540</td>\n",
       "      <td>15.310284</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0</td>\n",
       "      <td>159569</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 158166)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.515923</td>\n",
       "      <td>108.585989</td>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>153164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.000346</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df_test_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comment_text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>153164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>367.484899</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df_test_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>153164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.000346</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>153161</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.542530</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(-1, 89186)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802448</td>\n",
       "      <td>-0.361555</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>153161</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.579895</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(-1, 89186)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>-1.703070</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0</td>\n",
       "      <td>153161</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.558193</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(-1, 89186)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.683522</td>\n",
       "      <td>-0.670554</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>threat</td>\n",
       "      <td>0</td>\n",
       "      <td>153161</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.580913</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(-1, 89186)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.361793</td>\n",
       "      <td>-1.779620</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>insult</td>\n",
       "      <td>0</td>\n",
       "      <td>153161</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.559916</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(-1, 89186)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666402</td>\n",
       "      <td>-0.721203</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0</td>\n",
       "      <td>153161</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.577642</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(-1, 89186)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.423640</td>\n",
       "      <td>-1.545254</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Column  Null Values  Duplicate Values Data Type  Unique Values  \\\n",
       "0              id            0                 0    object         159571   \n",
       "1    comment_text            0                 0    object         159571   \n",
       "2           toxic            0            159569     int64              2   \n",
       "3    severe_toxic            0            159569     int64              2   \n",
       "4         obscene            0            159569     int64              2   \n",
       "5          threat            0            159569     int64              2   \n",
       "6          insult            0            159569     int64              2   \n",
       "7   identity_hate            0            159569     int64              2   \n",
       "8              id            0                 0    object         153164   \n",
       "9    comment_text            0                 0    object         153164   \n",
       "10             id            0                 0    object         153164   \n",
       "11          toxic            0            153161     int64              3   \n",
       "12   severe_toxic            0            153161     int64              3   \n",
       "13        obscene            0            153161     int64              3   \n",
       "14         threat            0            153161     int64              3   \n",
       "15         insult            0            153161     int64              3   \n",
       "16  identity_hate            0            153161     int64              3   \n",
       "\n",
       "    Min Text Length  Max Text Length  Mean Text Length  Median Text Length  \\\n",
       "0              15.0             21.0         16.000420                16.0   \n",
       "1               6.0           5000.0        396.593961               207.0   \n",
       "2               NaN              NaN               NaN                 NaN   \n",
       "3               NaN              NaN               NaN                 NaN   \n",
       "4               NaN              NaN               NaN                 NaN   \n",
       "5               NaN              NaN               NaN                 NaN   \n",
       "6               NaN              NaN               NaN                 NaN   \n",
       "7               NaN              NaN               NaN                 NaN   \n",
       "8               1.0             21.0         16.000346                16.0   \n",
       "9               1.0           5000.0        367.484899               182.0   \n",
       "10              1.0             21.0         16.000346                16.0   \n",
       "11              NaN              NaN               NaN                 NaN   \n",
       "12              NaN              NaN               NaN                 NaN   \n",
       "13              NaN              NaN               NaN                 NaN   \n",
       "14              NaN              NaN               NaN                 NaN   \n",
       "15              NaN              NaN               NaN                 NaN   \n",
       "16              NaN              NaN               NaN                 NaN   \n",
       "\n",
       "        Mean  Median         Mode  Range       Skew    Kurtosis  \\\n",
       "0        NaN     NaN          NaN    NaN        NaN         NaN   \n",
       "1        NaN     NaN          NaN    NaN        NaN         NaN   \n",
       "2   0.095844     0.0  (0, 144277)    1.0   2.745854    5.539784   \n",
       "3   0.009996     0.0  (0, 157976)    1.0   9.851722   95.057627   \n",
       "4   0.052948     0.0  (0, 151122)    1.0   3.992817   13.942760   \n",
       "5   0.002996     0.0  (0, 159093)    1.0  18.189001  328.843890   \n",
       "6   0.049364     0.0  (0, 151694)    1.0   4.160540   15.310284   \n",
       "7   0.008805     0.0  (0, 158166)    1.0  10.515923  108.585989   \n",
       "8        NaN     NaN          NaN    NaN        NaN         NaN   \n",
       "9        NaN     NaN          NaN    NaN        NaN         NaN   \n",
       "10       NaN     NaN          NaN    NaN        NaN         NaN   \n",
       "11 -0.542530    -1.0  (-1, 89186)    2.0   0.802448   -0.361555   \n",
       "12 -0.579895    -1.0  (-1, 89186)    2.0   0.381757   -1.703070   \n",
       "13 -0.558193    -1.0  (-1, 89186)    2.0   0.683522   -0.670554   \n",
       "14 -0.580913    -1.0  (-1, 89186)    2.0   0.361793   -1.779620   \n",
       "15 -0.559916    -1.0  (-1, 89186)    2.0   0.666402   -0.721203   \n",
       "16 -0.577642    -1.0  (-1, 89186)    2.0   0.423640   -1.545254   \n",
       "\n",
       "            Source  \n",
       "0         df_train  \n",
       "1         df_train  \n",
       "2         df_train  \n",
       "3         df_train  \n",
       "4         df_train  \n",
       "5         df_train  \n",
       "6         df_train  \n",
       "7         df_train  \n",
       "8     df_test_data  \n",
       "9     df_test_data  \n",
       "10  df_test_labels  \n",
       "11  df_test_labels  \n",
       "12  df_test_labels  \n",
       "13  df_test_labels  \n",
       "14  df_test_labels  \n",
       "15  df_test_labels  \n",
       "16  df_test_labels  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run integrity function on datasets:\n",
    "df_train_result = data_integrity_check(df_train, title='df_train')\n",
    "df_test_data_result = data_integrity_check(df_test_data, title='df_test_data')\n",
    "df_test_labels_result = data_integrity_check(df_test_labels, title='df_test_labels')\n",
    "\n",
    "# Concatenate the results for ease of reading:\n",
    "concat_checks = pd.concat([df_train_result, df_test_data_result, df_test_labels_result], ignore_index=True)\n",
    "concat_checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Dictionary:\n",
    "\n",
    "1. id: a unique identifier for that comment.\n",
    "2. comment_text: a string containing an example comment to train the model on.\n",
    "\n",
    "\n",
    "3. toxic: a binary numerical identifier to state if the comment contains malicious content.\n",
    "\n",
    "4. severe_toxic: a binary numerical identifier to state if the comment contains highly offensive malicious content.\n",
    "\n",
    "5. obscene: a binary numerical identifier to state if the comment contains curse words or not.\n",
    "\n",
    "6. threat: a binary numerical identifier to state if the comment contains a threat or not.\n",
    "\n",
    "7. insult: a binary numerical identifier to state if the comment contains a personal insult or not.\n",
    "\n",
    "8. identity_hate: a binary numerical identifier to state if the comment contains offensive material based on the recipients characteristics, e.g. racism, sexism, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First check:  [-1  0  1]\n",
      "Second check:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Training and test data look fine, but why do test_labels have 3 unique values instead of 2? \n",
    "for col in df_test_labels:\n",
    "    unique_values = df_test_labels[col].unique()\n",
    "print(f'First check: ', unique_values)\n",
    "\n",
    "# Aha, it follows a different convention. We need to clean this up to ensure it matches the others.\n",
    "# After a quick visual inspection, it seems the -1s are for positive (non-toxic) classifications.\n",
    "# I will change these to 0, to match the conventions of the training data.\n",
    "df_test_labels[df_test_labels == -1] = 1\n",
    "for col in df_test_labels:\n",
    "    unique_values = df_test_labels[col].unique()\n",
    "print(f'Second check: ', unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Null Values</th>\n",
       "      <th>Duplicate Values</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Min Text Length</th>\n",
       "      <th>Max Text Length</th>\n",
       "      <th>Mean Text Length</th>\n",
       "      <th>Median Text Length</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Range</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>153164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.000346</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>153162</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 147074)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710831</td>\n",
       "      <td>20.192188</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>153162</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 152797)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.355616</td>\n",
       "      <td>412.356502</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0</td>\n",
       "      <td>153162</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 149473)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.206614</td>\n",
       "      <td>36.522538</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>threat</td>\n",
       "      <td>0</td>\n",
       "      <td>153162</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 152953)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.887009</td>\n",
       "      <td>720.920687</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insult</td>\n",
       "      <td>0</td>\n",
       "      <td>153162</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 149737)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.458872</td>\n",
       "      <td>39.717540</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0</td>\n",
       "      <td>153162</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 152452)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.564574</td>\n",
       "      <td>210.129547</td>\n",
       "      <td>df_test_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column  Null Values  Duplicate Values Data Type  Unique Values  \\\n",
       "0             id            0                 0    object         153164   \n",
       "1          toxic            0            153162     int64              2   \n",
       "2   severe_toxic            0            153162     int64              2   \n",
       "3        obscene            0            153162     int64              2   \n",
       "4         threat            0            153162     int64              2   \n",
       "5         insult            0            153162     int64              2   \n",
       "6  identity_hate            0            153162     int64              2   \n",
       "\n",
       "   Min Text Length  Max Text Length  Mean Text Length  Median Text Length  \\\n",
       "0              1.0             21.0         16.000346                16.0   \n",
       "1              NaN              NaN               NaN                 NaN   \n",
       "2              NaN              NaN               NaN                 NaN   \n",
       "3              NaN              NaN               NaN                 NaN   \n",
       "4              NaN              NaN               NaN                 NaN   \n",
       "5              NaN              NaN               NaN                 NaN   \n",
       "6              NaN              NaN               NaN                 NaN   \n",
       "\n",
       "       Mean  Median         Mode  Range       Skew    Kurtosis          Source  \n",
       "0       NaN     NaN          NaN    NaN        NaN         NaN  df_test_labels  \n",
       "1  0.039761     0.0  (0, 147074)    1.0   4.710831   20.192188  df_test_labels  \n",
       "2  0.002396     0.0  (0, 152797)    1.0  20.355616  412.356502  df_test_labels  \n",
       "3  0.024098     0.0  (0, 149473)    1.0   6.206614   36.522538  df_test_labels  \n",
       "4  0.001378     0.0  (0, 152953)    1.0  26.887009  720.920687  df_test_labels  \n",
       "5  0.022375     0.0  (0, 149737)    1.0   6.458872   39.717540  df_test_labels  \n",
       "6  0.004649     0.0  (0, 152452)    1.0  14.564574  210.129547  df_test_labels  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redo integrity check:\n",
    "df_test_labels_result = data_integrity_check(df_test_labels, title='df_test_labels')\n",
    "df_test_labels_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0                143346\n",
       "1      0             0        0       0       0                  5666\n",
       "                     1        0       1       0                  3800\n",
       "                                      0       0                  1758\n",
       "                     0        0       1       0                  1215\n",
       "       1             1        0       1       0                   989\n",
       "       0             1        0       1       1                   618\n",
       "0      0             1        0       0       0                   317\n",
       "                     0        0       1       0                   301\n",
       "1      1             1        0       1       1                   265\n",
       "0      0             1        0       1       0                   181\n",
       "1      1             1        0       0       0                   158\n",
       "       0             0        0       0       1                   136\n",
       "                                      1       1                   134\n",
       "                     1        1       1       0                   131\n",
       "                     0        1       0       0                   113\n",
       "       1             1        1       1       0                    64\n",
       "       0             1        1       1       1                    56\n",
       "0      0             0        0       0       1                    54\n",
       "1      1             0        0       0       0                    41\n",
       "       0             1        0       0       1                    35\n",
       "       1             1        1       1       1                    31\n",
       "0      0             0        0       1       1                    28\n",
       "                              1       0       0                    22\n",
       "                     1        0       1       1                    18\n",
       "1      0             0        1       1       0                    16\n",
       "       1             0        0       1       0                    14\n",
       "                              1       0       0                    11\n",
       "       0             1        1       0       0                    11\n",
       "                     0        1       0       1                     7\n",
       "       1             0        0       1       1                     7\n",
       "                     1        0       0       1                     6\n",
       "                              1       0       0                     4\n",
       "                     0        0       0       1                     3\n",
       "       0             0        1       1       1                     3\n",
       "0      0             1        0       0       1                     3\n",
       "                     0        1       1       0                     3\n",
       "                     1        1       1       0                     2\n",
       "                                      0       0                     2\n",
       "1      1             0        1       0       1                     1\n",
       "                                      1       0                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the feature classes like?\n",
    "df_train[df_train.columns[2:]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay that seems to have done the job. Worth noting a major class imbalance between 16,225 toxic and 143,346 non-toxic scoring comments which might bias the training of models. How do the other two datasets compare, now that we think about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0                146921\n",
       "1      0             1        0       1       0                  1932\n",
       "                     0        0       0       0                  1710\n",
       "                     1        0       0       0                   854\n",
       "                     0        0       1       0                   539\n",
       "                     1        0       1       1                   361\n",
       "       1             1        0       1       0                   176\n",
       "                                              1                   116\n",
       "       0             0        0       1       1                    81\n",
       "                                      0       1                    67\n",
       "                     1        1       1       0                    65\n",
       "0      0             0        0       1       0                    64\n",
       "1      0             0        1       0       0                    50\n",
       "0      0             1        0       0       0                    49\n",
       "1      1             1        0       0       0                    28\n",
       "       0             1        1       1       1                    25\n",
       "       1             1        1       1       0                    24\n",
       "       0             1        0       0       1                    20\n",
       "0      0             1        0       1       0                    15\n",
       "1      1             1        1       1       1                    14\n",
       "0      0             0        0       0       1                    14\n",
       "1      0             0        1       1       0                     9\n",
       "                     1        1       0       0                     6\n",
       "0      0             0        1       0       0                     5\n",
       "1      0             0        1       0       1                     4\n",
       "       1             0        1       0       1                     4\n",
       "                     1        1       0       0                     4\n",
       "0      0             0        0       1       1                     4\n",
       "                     1        0       1       1                     1\n",
       "1      1             1        0       0       1                     1\n",
       "0      0             0        1       1       0                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balance in test_labels:\n",
    "df_test_labels[df_test_labels.columns[1:]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data labels seem to have the same issue, far more non-toxic than toxic comments. This is something to keep in mind when training or doing classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\r\\nWhy the edits made under my use...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\r\\n\\r\\nThat...\n",
       "159568    Spitzer \\r\\n\\r\\nUmm, theres no actual article ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\r\\nAnd ... I really don't think you understa...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\Anaconda3\\envs\\DeepLearn_Env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\olive\\Anaconda3\\envs\\DeepLearn_Env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'should', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into data (X) and features to predict (y):\n",
    "X = df_train['comment_text']\n",
    "y = df_train[df_train.columns[2:]].values\n",
    "\n",
    "# Now we need to tokenize & vectorize everything, using NLTK and TF-IDF:\n",
    "X_processed = feature_vectorizer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That feature_vectorizer function is designed to preprocess a corpus of text data by tokenizing it, removing stopwords, and generating a document-term matrix using the CountVectorizer from scikit-learn. It first defines a list of stopwords and a whitelist of exceptions, then removes stopwords from the corpus while preserving those in the whitelist. \n",
    "The function utilizes the CountVectorizer with specific configurations such as lowercase conversion, tokenization using NLTK's word_tokenize function, minimum document frequency of 2, and unigram to bigram n-gram range. Additionally, it applies the TF-IDF transformation to the resulting document-term matrix to weigh the importance of terms in the corpus. Finally, it returns the processed corpus in its vectorized form suitable for further analysis or modeling tasks like we want to do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 678726)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check vectorizer worked as intended:\n",
    "X_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should now represent a document-term matrix with 159,571 rows and 678,726 features produced from TF-IDF. \n",
    "\n",
    "TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents. It has many uses, most importantly in automated text analysis, and is very useful for scoring words in machine learning algorithms for Natural Language Processing (NLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However it is probably worth doing some dimensionality reduction because X_processed has an enormous dimensionality at 159,571 rows and 678,726 columns! \n",
    "Dimensionality reduction is crucial in NLP for coping with high-dimensional data, typical of large vocabularies or intricate word embeddings. This helps us to handle the \"curse of dimensionality\" which refers to challenges with high-dimensional data, including data sparsity which affects our ability to make statistical inferences, increased computational complexity which bloats execution times, and heightened risk of overfitting which leads to poor model performance on new data. By compressing the feature space while preserving essential information, these techniques improve computational efficiency, enhance model generalization, and facilitate insightful data exploration and interpretation.\n",
    "\n",
    "For this use case, I suggest Latent Semantic Analysis (LSA) which is an unsupervised learning technique to extract and represent the underlying semantic structure of textual data by constructing a mathematical model of the relationships between terms and documents in a corpus. \n",
    "\n",
    "LSA uses a matrix factorization method, typically Singular Value Decomposition (SVD), to decompose a term-document matrix into lower-dimensional representations. In the context of LSA and natural language processing, SVD is commonly applied to decompose the term-document matrix into three matrices: the left singular vectors matrix, the diagonal singular values matrix, and the right singular vectors matrix. These matrices represent the relationships between terms and documents in a lower-dimensional space, where the singular values capture the importance of each dimension. \n",
    "\n",
    "SVD enables dimensionality reduction by retaining only the most significant singular values and their corresponding singular vectors, thus revealing the underlying latent semantic structure of the data. These representations, known as latent semantic dimensions, capture the latent relationships between terms and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Latent Semantic Analysis:\n",
    "lsa_tool = TruncatedSVD(n_components=400, n_iter=100, random_state=123)\n",
    "# The above will reduce X_vectorized from 678,726 to 400 features.\n",
    "# We can always return to modify this later on if needed or wanted.\n",
    "\n",
    "# Fit and transform the vectorized data\n",
    "X_lsa = lsa_tool.fit_transform(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 400)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect output:\n",
    "X_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Output on training data X_processed converted to Pandas dataframe and saved as CSV.\n"
     ]
    }
   ],
   "source": [
    "# Looks good, now let's save it for convenience.\n",
    "df_lsa = pd.DataFrame(X_lsa)\n",
    "df_lsa.to_csv('lsa_train_output.csv', index=False)\n",
    "print(f'LSA Output on training data X_processed converted to Pandas dataframe and saved as CSV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, let's do the test data too:\n",
    "X = df_test_data['comment_text']\n",
    "y = df_test_labels[df_test_labels.columns[1:]]\n",
    "\n",
    "# Run the vectorizer again:\n",
    "X_test_processed = feature_vectorizer(X)\n",
    "\n",
    "# Need to ensure test data has same feature shape as training data.\n",
    "# So we repeat LSA for dimensionality reduction:\n",
    "X_test_lsa = lsa_tool.fit_transform(X_test_processed)\n",
    "\n",
    "# Inspect output:\n",
    "X_test_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Output on test data X_processed converted to Pandas dataframe and saved as CSV.\n"
     ]
    }
   ],
   "source": [
    "# Looks good, now let's save it for convenience.\n",
    "df_test_lsa = pd.DataFrame(X_test_lsa)\n",
    "df_test_lsa.to_csv('lsa_test_output.csv', index=False)\n",
    "print(f'LSA Output on test data X_processed converted to Pandas dataframe and saved as CSV.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
