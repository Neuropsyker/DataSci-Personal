{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrying on from the previous Supervised SA notebook, this one concerns classification modelling, hyperparameter tuning, and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import email\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import classify\n",
    "from sklearn import metrics, preprocessing, feature_extraction, linear_model, naive_bayes, ensemble, pipeline, svm, model_selection, decomposition\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import tree, datasets\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Ensure NLTK libraries up to date:\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tell TensorFlow to run all deep learning on GPU:\n",
    "tf.config.set_soft_device_placement\n",
    "tf.test.is_built_with_cuda()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Tell TensorFlow to run all deep learning on GPU:\n",
    "tf.config.set_soft_device_placement\n",
    "tf.test.is_built_with_cuda()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor and vectorizer, to produce TF-IDF document matrix:\n",
    "def feature_vectorizer(corpus):\n",
    "    sa_stop_words = nltk.corpus.stopwords.words('english')\n",
    "    ''' Create a list of exceptions, as these stopwords may change a sentence's sentiment if removed. '''\n",
    "    sa_white_list = ['what', 'but', 'if', 'because', 'as', 'until', 'against', 'up', 'down', 'in', 'out',\n",
    "                    'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'why',\n",
    "                    'how', 'all', 'any', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
    "                    'same', 'so', 'than', 'too', 'can', 'will', 'just', 'don', 'should']\n",
    "    ''' Remove stop words except for those specified in the white list. '''\n",
    "    sa_stop_words = [sw for sw in sa_stop_words if sw not in sa_white_list]\n",
    "    ''' Instantiate the vectorizer. '''\n",
    "    count_vectorizer = feature_extraction.text.CountVectorizer(\n",
    "        lowercase = True,\n",
    "        tokenizer = nltk.word_tokenize,\n",
    "        min_df=2, # this means the term frequency must be 2 or higher.\n",
    "        ngram_range=(1,2),\n",
    "        stop_words=sa_stop_words\n",
    "    )\n",
    "    ''' Run the vectorizer on the body of text ('corpus'). '''\n",
    "    processed_corpus = count_vectorizer.fit_transform(corpus)\n",
    "    processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform(processed_corpus)\n",
    "    return processed_corpus\n",
    "\n",
    "def data_integrity_check(df, title='', include_non_numeric=True):\n",
    "    '''Check for nulls, duplicates, etc and perform basic EDA.'''\n",
    "    results = []\n",
    "    for col in df:\n",
    "        result = {\n",
    "            'Column': col,\n",
    "            'Null Values': df[col].isnull().sum(),\n",
    "            'Duplicate Values': df[col].duplicated().sum(),\n",
    "            'Data Type': df[col].dtype\n",
    "        }\n",
    "        if include_non_numeric or df[col].dtype in ['int64', 'float64']:\n",
    "            result['Unique Values'] = df[col].nunique()\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                result['Mean'] = df[col].mean()\n",
    "                result['Median'] = df[col].median()\n",
    "                result['Mode'] = stats.mode(df[col])\n",
    "                result['Range'] = df[col].max() - df[col].min()\n",
    "                result['Skew'] = df[col].skew()\n",
    "                result['Kurtosis'] = df[col].kurtosis()\n",
    "        if df[col].dtype == 'object':  \n",
    "            result['Min Text Length'] = df[col].str.len().min()\n",
    "            result['Max Text Length'] = df[col].str.len().max()\n",
    "            '''Calculate mean and median text lengths'''\n",
    "            text_lengths = df[col].str.len()\n",
    "            result['Mean Text Length'] = np.mean(text_lengths)\n",
    "            result['Median Text Length'] = np.median(text_lengths)\n",
    "        results.append(result)\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df['Source'] = title\n",
    "    return result_df\n",
    "\n",
    "# Prints performance metrics for classifiers:\n",
    "def print_classification_report(y_true, y_pred):\n",
    "    '''Get a classification report for performance metric inspection.'''\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 400)\n",
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "# Import dataset from preprocessing outputs:\n",
    "df_sa = pd.read_csv('lsa_train_output.csv')\n",
    "print(df_sa.shape)\n",
    "\n",
    "# Reimport training labels:\n",
    "df_train = pd.read_csv('sa_train.csv')\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple multi-output logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR Model Performance: 0.9113\n",
      "Best LR Model Parameters: {'estimator__C': 0.5, 'estimator__class_weight': None, 'estimator__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split:\n",
    "X_training = df_sa\n",
    "y = df_train[df_train.columns[2:]].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y, test_size = 0.3, random_state=123)\n",
    "\n",
    "# Define common hyperparameter settings for GridSearch:\n",
    "param_grid_lr = {\n",
    "    'estimator__penalty': ['l1', 'l2'],\n",
    "    'estimator__C': [0.001, 0.01, 0.1, 0.25, 0.5],\n",
    "    'estimator__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "# Instantiate classifiers:\n",
    "base_LR_classifier = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Wrap classifiers with MultiOutput:\n",
    "multi_classifier_lr = MultiOutputClassifier(base_LR_classifier)\n",
    "\n",
    "# Grid search for Logistic Regression\n",
    "grid_search_lr = GridSearchCV(multi_classifier_lr, param_grid_lr, n_jobs=10) \n",
    "# n_jobs=10 to use 10 of my PC's 14 CPU cores for faster computation.\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "print('Best LR Model Performance: {:.4f}'.format(grid_search_lr.best_score_))\n",
    "print('Best LR Model Parameters:', grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Performance' refers to accuracy which is a single metric that represents the overall correctness of the classifier across all classes. While accuracy is easy to interpret and can provide a quick overview of performance, it may not be suitable for imbalanced datasets where the class distribution is skewed.\n",
    "\n",
    "Time to run the classifiers based on those GridSearch outputs, see the code in the next block below.\n",
    "I am rounding the probability predictions to a whole number to ensure consistency with binary format of training data (0 or 1 for comment features).\n",
    "I am also printing a classification report so that we get a range of metrics other than just accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Toxic       0.88      0.54      0.67      4478\n",
      "Severely Toxic       0.51      0.19      0.28       476\n",
      "       Obscene       0.90      0.59      0.71      2499\n",
      "        Threat       0.00      0.00      0.00       139\n",
      "        Insult       0.81      0.46      0.58      2321\n",
      " Identity Hate       0.56      0.08      0.14       426\n",
      "\n",
      "     micro avg       0.86      0.49      0.62     10339\n",
      "     macro avg       0.61      0.31      0.40     10339\n",
      "  weighted avg       0.83      0.49      0.61     10339\n",
      "   samples avg       0.05      0.04      0.04     10339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'Score' method in scikit-learn typically reports the accuracy of the model on the given dataset. \n",
    "# We need more metrics to better judge each model:\n",
    "\n",
    "# Print classes with matching number for reference:\n",
    "class_mapping = {\n",
    "        0: 'Toxic',\n",
    "        1: 'Severely Toxic',\n",
    "        2: 'Obscene',\n",
    "        3: 'Threat',\n",
    "        4: 'Insult',\n",
    "        5: 'Identity Hate'\n",
    "        }\n",
    "\n",
    "# Retrieve best parameters from GridSearch:\n",
    "best_lr_params = grid_search_lr.best_params_\n",
    "\n",
    "# Remove 'estimator__' prefix from the parameter names to prevent TypeError:\n",
    "best_lr_params_cleaned = {key.replace('estimator__', ''): value for key, value in best_lr_params.items()}\n",
    "\n",
    "# Instantiate LogisticRegression with best parameters:\n",
    "best_lr_classifier = LogisticRegression(**best_lr_params_cleaned, solver='liblinear')\n",
    "\n",
    "# Wrap LogisticRegression in MultiOutputClassifier:\n",
    "best_multi_classifier_lr = MultiOutputClassifier(best_lr_classifier)\n",
    "\n",
    "# Fit the classifier to the training data:\n",
    "best_multi_classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# How accurately can it predict reserved test data in the train dataset?\n",
    "y_pred_lr = best_multi_classifier_lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr, target_names=class_mapping.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the performance metrics for the logistic regression classifier:\n",
    "\n",
    "_Precision:_ measures the proportion of correctly predicted positive instances among all instances predicted as positive.\n",
    "- For class 0 (Toxic), the precision is 0.88, indicating that among all instances predicted as toxic, 88% are correctly classified.\n",
    "- For class 1 (Severely Toxic), the precision is 0.51, meaning that only 51% of instances predicted as severely toxic are actually classified correctly.\n",
    "- For class 2 (Obscene), the precision is 0.90, indicating a high proportion of correctly predicted obscene instances.\n",
    "- For class 3 (Threat), the precision is 0.00, suggesting that none of the instances predicted as threats are correctly classified.\n",
    "- For class 4 (Insult), the precision is 0.81, indicating a relatively high proportion of correctly predicted insult instances.\n",
    "- For class 5 (Identity Hate), the precision is 0.56, indicating 56% were classified accurately but with low recall indicating false positives.\n",
    "\n",
    "_Recall:_ measures the proportion of correctly predicted positive instances among all actual positive instances.\n",
    "- The recall values are generally low across all classes, indicating that the classifier misses a significant portion of actual positive instances.\n",
    "- For class 0 (Toxic), the recall is 0.54, meaning that only 54% of actual toxic instances are correctly classified.\n",
    "- For class 1 (Severely Toxic), the recall is 0.19, indicating that only 19% of actual severely toxic instances are correctly classified.\n",
    "- For class 2 (Obscene), the recall is 0.59, suggesting that nearly half of the actual obscene instances are correctly classified.\n",
    "- For class 3 (Threat), the recall is 0.00, indicating that none of the actual threat instances are correctly classified.\n",
    "- For class 4 (Insult), the recall is 0.46, indicating that 46% of actual insult instances are correctly classified.\n",
    "- For class 5 (Identity Hate), the recall is 0.08, suggesting that only a very small proportion of actual identity hate instances are correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly explain the other above metrics:\n",
    "\n",
    "- Macro-average: This average calculates the metric independently for each class and then takes the unweighted mean of the metrics. It gives equal weight to each class, regardless of its size. Macro-average is useful when you want to ensure that the classifier performs well across all classes, regardless of their prevalence.\n",
    "\n",
    "- Micro-average: This average aggregates the contributions of all classes to compute the average metric. It gives equal weight to each prediction, regardless of the class.\n",
    "Micro-average is useful when you want to evaluate the overall performance of the classifier, taking into account the imbalance in class frequencies.\n",
    "\n",
    "- Weighted average: This average calculates the metric for each class and then takes a weighted average based on the number of true instances for each class. It gives more weight to classes with more instances, making it suitable for imbalanced datasets. Weighted average is useful when you want to prioritize the performance of the majority classes while still considering the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given what we know about this dataset from the Preprocessing workbook, I will use Micro Average and Weighted Average to judge overall performance.\n",
    "\n",
    "_Micro Average:_\n",
    "- Precision (0.86): This indicates that, on average, 86% of the instances predicted as positive are indeed positive across all classes. It's a measure of the overall correctness of the positive predictions.\n",
    "- Recall (0.49): This indicates that, on average, 49% of the actual positive instances are correctly identified by the classifier across all classes. It's a measure of the classifier's ability to capture positive instances.\n",
    "- F1-score (0.62): This is the harmonic mean of precision and recall and provides a balanced measure of the classifier's performance. It takes into account both false positives and false negatives and is useful for assessing overall classifier performance.\n",
    "\n",
    "_Weighted Average:_\n",
    "- Precision (0.83): This indicates the average precision across all classes, with each class's contribution weighted by its support (the number of true instances). Classes with more instances have a greater impact on this metric.\n",
    "- Recall (0.49): This indicates the average recall across all classes, with each class's contribution weighted by its support. It's a measure of the classifier's ability to capture positive instances, accounting for class imbalance.\n",
    "- F1-score (0.61): This is the weighted average of F1-scores across all classes, with each class's contribution weighted by its support. It provides a balanced measure of the classifier's performance, considering both precision and recall while accounting for class imbalance.\n",
    "\n",
    "In summary, the logistic regression classifier demonstrates strong precision but relatively low recall in predicting the multi-label classes of toxic comments, severely toxic comments, obscene content, threats, insults, and identity hate in the test section of the training dataset. While the classifier achieves high precision in identifying positive instances, indicating a low rate of false positives across classes, its recall is notably lower, suggesting that it misses a significant portion of actual positive instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data check:  [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Okay, how does this trained LogReg perform on the test_dataset now?\n",
    "\n",
    "# Classification labels for test data:\n",
    "df_test_labels = pd.read_csv('sa_test_labels.csv')\n",
    "\n",
    "# Test data with text only:\n",
    "df_test_data = pd.read_csv('lsa_test_output.csv')\n",
    "\n",
    "# Ensure binary nature of test labels:\n",
    "df_test_labels[df_test_labels == -1] = 1\n",
    "for col in df_test_labels:\n",
    "    unique_values = df_test_labels[col].unique()\n",
    "print(f'Data check: ', unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Toxic       0.67      0.14      0.23     95276\n",
      "Severely Toxic       0.64      0.00      0.00     89553\n",
      "       Obscene       0.64      0.06      0.11     92877\n",
      "        Threat       0.00      0.00      0.00     89397\n",
      "        Insult       0.65      0.02      0.04     92613\n",
      " Identity Hate       0.48      0.00      0.00     89898\n",
      "\n",
      "     micro avg       0.66      0.04      0.07    549614\n",
      "     macro avg       0.51      0.04      0.06    549614\n",
      "  weighted avg       0.52      0.04      0.07    549614\n",
      "   samples avg       0.09      0.03      0.04    549614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input data/feature split:\n",
    "X_testing = df_test_data\n",
    "y_true = df_test_labels[df_test_labels.columns[1:]]\n",
    "\n",
    "# Run LR classifier on test dataset:\n",
    "y_pred_lr = best_multi_classifier_lr.predict(X_testing)\n",
    "print(classification_report(y_true, y_pred_lr, target_names=class_mapping.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset generally shows significantly higher precision, recall, and F1-scores compared to the testing dataset across all classes.\n",
    "\n",
    "Class imbalance might be a concern, especially noticeable in the testing dataset where recall is quite low for most classes, indicating that the model struggles to correctly identify instances of these classes. This would make sense because a visual inspection of the dataset confirms that a majority of the sample comments are non-toxic.\n",
    "\n",
    "There's a significant drop in performance metrics between the training and testing datasets, indicating potential overfitting of the model to the training data. The model seems to generalize poorly to unseen data, suggesting the need for further model refinement or data augmentation techniques to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix LogReg:\n",
      "\n",
      "Class Toxic:\n",
      "[[51278  6610]\n",
      " [82098 13178]]\n",
      "\n",
      "Class Severely Toxic:\n",
      "[[63593    18]\n",
      " [89521    32]]\n",
      "\n",
      "Class Obscene:\n",
      "[[57090  3197]\n",
      " [87240  5637]]\n",
      "\n",
      "Class Threat:\n",
      "[[63767     0]\n",
      " [89397     0]]\n",
      "\n",
      "Class Insult:\n",
      "[[59561   990]\n",
      " [90789  1824]]\n",
      "\n",
      "Class Identity Hate:\n",
      "[[63253    13]\n",
      " [89886    12]]\n"
     ]
    }
   ],
   "source": [
    "# Let's get a look at a confusion matrix:\n",
    "cm_lr = multilabel_confusion_matrix(y_true, y_pred_lr)\n",
    "\n",
    "# Printing confusion matrices:\n",
    "print(\"\\nConfusion Matrix LogReg:\")\n",
    "for i, cm in enumerate(cm_lr):\n",
    "    class_name = class_mapping[i]\n",
    "    print(f\"\\nClass {class_name}:\\n{cm}\")"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed that different resources report different conventions with the orientation of confusion matrices.\n",
    "\n",
    "To help with understanding output: https://towardsdatascience.com/understanding-the-confusion-matrix-from-scikit-learn-c51d88929c79\n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the confusion matrix output from its predictions of the test data:\n",
    "\n",
    "Overall the logistic regression classifier demonstrates challenges in correctly classifying instances across all classes, with a notable imbalance between true negatives (TN), false negatives (FN), and true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Which convention does Sklearn follow?\n",
    "y_true = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "y_pred = [1, 1, 1, 0, 1, 0, 1, 0]\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could spend lots of time tweaking this logistic regressor, but I was not expecting it to perform very well with this sort of task. Instead, it was just a starting point to consider other more advanced models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
